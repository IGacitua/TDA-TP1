\section{Algoritmo para asignar operaciones a intervalos}

\subsection{Código}


A continuación se muestra el código de la solución greedy del problema. 


\lstinputlisting[language=Python,firstline=8]{../src/moleFinder.py}

% Si queremos importar el código directo desde un archivo, podemos hacer lo siguiente: 

% \lstinputlisting[language=Python]{code/maximo_iterativo.py}

% Ventaja: evitamos copiar y pegar, y que si en un momento se modifique el algoritmo (reentrega, o la razón que fuere) no nos tengamos que acordar de esto más allá de compilar. 

% Desventaja: tenemos que asegurarnos de modularizar el código en archivos en función de cómo queremos mostrar el informe. Por otro lado, esto tiene especial sentido si estamos trabajando todo de forma local. Es decir, en el caso que no usemos Overleaf, porque sino implica tener que copiar el código de todas formas. 

% Mencionamos esta alternativa para que sepan que existe, ustedes definen cómo prefieren trabajar con esto. No nos interesa el código del informe, sólo el pdf resultante. 

\subsection{Análisis de complejidad}

La complejidad del algoritmo planteado posee dos partes identificables, el ordenamiento mediante MergeSort de los timestamp por tiempo de fin y la asignacion de las transacciones a un timestamp

Primero, hagamos un rapido analisis del ordenamiento MergeSort, este algoritmo divide el arreglo en subarreglos de la mitad de tamaño hasta llegar a un unico elemento, el cual se considera ordenado, luego combina los mismos de manera ordenada hasta llegar a nuestro arrreglo original ordenado en su totalidad. Si hablamos solo de temas de complejidad esta parte de nuestra respuesta tiene $\mathcal{O}\left(n \log n\right)$.

Por otro lado tenemos la parte principal del algoritmo, lo que busca es asignar cada transacción a un timestamp diferente. Consigue esto tomando y verificando dentro de que timestamps se encuentra y asociándolo al que termina antes, y esto se realiza por cada transacción. Por lo tanto podemos deducir que esta parte del algoritmo es de $\mathcal{O}(n^2)$.

Si vemos el algoritmo en su totalidad tiene $\mathcal{O}\left(n \log n\right)$ + $\mathcal{O}(n^2)$, pero cuando nos vamos a $n$ grandes, que son los casos que nos interesan para el análisis de la complejidad observamos que el algoritmo es de $\mathcal{O}(n^2)$

Como se va a ver en las mediciones, esto no es exacto sino que es un aproximado en los peores casos

(Lo dejo por si agregamos una ecuacion, asi esta el ejemplo)
\begin{equation*} %nota: el asterisco es para que no aparezca el (1) al lado de la ecuación
    \mathcal{T}(n) = 2 \mathcal{T}\left(\frac{n}{2}\right) + \mathcal{O}(n)
\end{equation*}

